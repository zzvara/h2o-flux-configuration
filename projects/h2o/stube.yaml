apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: stube
  namespace: experimental
spec:
  type: Scala
  mode: cluster
  image: "zzvara/spark-youtube:latest"
  imagePullPolicy: Always
  mainClass: hu.sztaki.spark.youtube.Job
  mainApplicationFile: "local:///opt/spark/dependencies/application.jar"
  sparkVersion: "3.0.1"
  hadoopConfigMap: spark-default-configuration
  sparkConf:
    "spark.driver.extraJavaOptions": "-Dlog4j.configurationFile=file:///opt/spark/configuration/log4j2.properties -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager"
    "spark.default.parallelism": "2"
    "spark.executor.extraJavaOptions": "-XX:ParallelGCThreads=6 -XX:ConcGCThreads=2 -XX:+UseG1GC -XX:InitiatingHeapOccupancyPercent=60 -Dlog4j.configurationFile=file:///opt/spark/configuration/log4j2.properties -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager"
    "spark.kubernetes.executor.deleteOnTermination": "false"
    "spark.serializer": "org.apache.spark.serializer.JavaSerializer"
    "spark.executor.extraClassPath": "/opt/spark/configuration:/opt/spark/dependencies/application.jar"
    "spark.driver.extraClassPath": "/opt/spark/configuration:/opt/spark/dependencies/application.jar"
  restartPolicy:
    type: Never
  volumes:
    - name: configuration
      configMap:
        name: h2o-stube-spark-configuration
  driver:
    cores: 1
    memory: "2048m"
    labels:
      version: 3.1.1
    serviceAccount: spark-operator-experimental
    volumeMounts:
      - name: configuration
        mountPath: /opt/spark/configuration
  executor:
    cores: 2
    instances: 1
    memory: "2048m"
    labels:
      version: 3.1.1
    volumeMounts:
      - name: configuration
        mountPath: /opt/spark/configuration